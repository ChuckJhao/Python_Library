{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas to processing dataset\n",
    "\n",
    "row: index 0,1,2,3... 每一筆資料 <br>\n",
    "column: 欄位名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = pd.Series([1, 3, 5, np.nan])\n",
    "print(x)\n",
    "print(x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start='20130101', end='20131231', freq='D')  #間隔為天\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start='20130101', end='20131231', freq='M')  #間隔為月\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[np.random.randint(1,100) for j in range(4)] for i in range(12)], index=dates, columns=list('ABCD'))   #4列亂數\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two dataframe using append\n",
    "df1 = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
    "df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
    "df3=df1.append(df2,ignore_index=True)\n",
    "print(df3)\n",
    "\n",
    "print(df3.shape)\n",
    "print(df3.columns)\n",
    "\n",
    "print(df3['B'])\n",
    "print(df3['A'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas datafreame format\n",
    "x = [{'a':1, 'b':2},{'a':3,'b':4,'c':5}]\n",
    "\n",
    "df=pd.DataFrame(x)\n",
    "print(df)\n",
    "\n",
    "print(df['b'])\n",
    "df['t0']=100\n",
    "\n",
    "#df['t0']=0\n",
    "df['t1']=0\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(x)\n",
    "print(y['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas create a datafreame from dict \n",
    "\n",
    "\n",
    "x =[ {'國文':100, '英文':60,'總分':160},{'國文':95,'英文':85,'總分':180},{'國文':74,'英文':100,'總分':174}]\n",
    "\n",
    "df=pd.DataFrame(x, index = ['小美', '小華','小明'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "pd.DataFrame(x, index = ['小美', '小華','小明'],columns=x[0].keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[i] for i in range(10)], columns=['num'])\n",
    "print(df)\n",
    "def powers(x):\n",
    "    return x, x**2, x**3, x**4, x**5, x**6\n",
    "\n",
    "df['p1'], df['p2'], df['p3'], df['p4'], df['p5'], df['p6'] = \\\n",
    "    zip(*df['num'].map(powers))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Date':pd.date_range('2018-8-1','2018-8-9')})\n",
    "\n",
    "df['Week_Number'] = df['Date'].dt.week\n",
    "\n",
    "#df.head()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#index_col=int, to specify int column as the index (row names)\n",
    "#index_col=False, to force pandas to _not_ use the first column as the index (row names)\n",
    "\n",
    "pd.read_csv('Homework\\HW1\\hw1_data.csv', index_col = 0) #use first column as the index (row names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list header name & index name\n",
    "df=pd.read_csv('Homework\\HW1\\hw1_data.csv', index_col = 0)\n",
    "#list header name & index name\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "print(df.index)\n",
    "print(len(df.index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#only read some columns and number of row\n",
    "cols=[\"class\",\"male population\", \"female population\"]\n",
    "\n",
    "#index_col: csv 第幾列為欄位名稱, nrows: 讀幾列\n",
    "pd.read_csv('Homework\\HW1\\hw1_data.csv', index_col = 0,usecols=cols,nrows=4)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.columns)\n",
    "#欄位有那些是列出的?\n",
    "df.columns.isin(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['male population']  # display specific column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['male population'] >=2000     # display a specific column, and its value is larger than or equal toi 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting Data Using Criteria\n",
    "'''\n",
    "Equals: ==\n",
    "Not equals: !=\n",
    "Greater than, less than: > or <\n",
    "Greater than or equal to >=\n",
    "Less than or equal to <=\n",
    "'''\n",
    "df[df['male population'] >=2000]\n",
    "    # display specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subsetting Data Using Criteria\n",
    "df[(df['male population'] >=2000) & (df['male smoke percentage'] <= 25.0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc: indexing via labels or integers\n",
    "#iloc: indexing via integers\n",
    "\n",
    "df.iloc[0:3, 1:4]\n",
    "df.iloc[2,1]  #49.6\n",
    "df.loc[['Education level','senior high']]\n",
    "df.iloc[0:2]\n",
    "df.iloc[-1:, 0] # last row of column 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slicing Subsets of Rows \n",
    "df=pd.read_csv('Homework\\HW1\\hw1_data.csv', index_col = 0)\n",
    "df['female population']['junior high']    #1498.0\n",
    "df['male population']['university']    #2881.0\n",
    "df[:3]  # access the first thress rows\n",
    "df[1:3]   # row 1 and row 2\n",
    "df[-3:]   # last 3 rows\n",
    "\n",
    "df.head()  # first 5 rows\n",
    "\n",
    "# copy the surveys dataframe so we don't modify the original DataFrame\n",
    "df_copy = df\n",
    "# set the first three rows of data in the DataFrame to 0\n",
    "df_copy[0:10] = 0\n",
    "print(df_copy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### A mask can be useful to locate where a particular subset of values exist or \n",
    "#don't exist - for example, NaN, or \"Not a Number\" values.\n",
    "print(df)\n",
    "df[:3].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##To select just the rows with NaN values, we can use the .any method\n",
    "df[pd.isnull(df).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can run isnull on a particular column\n",
    "a=df[pd.isnull(df).any(axis=1)][['male population','female population']]\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Referencing Objects vs Copying Objects in Python\n",
    "\n",
    "#這樣只是Reference ,不是copy新的一份\n",
    "\n",
    "copy_df=df\n",
    "copy_df.isnull()\n",
    "copy_df[copy_df.isnull()]=0\n",
    "print(copy_df['male population'])\n",
    "print(df['male population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy dataframe, using df.copy()\n",
    "\n",
    "copy_df=df['male population'].copy()\n",
    "copy_df.isnull()\n",
    "copy_df[copy_df.isnull()]=0\n",
    "print(copy_df)\n",
    "print(df['male population'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[df['male population'] >=2000]\n",
    "x=x.as_matrix()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two dataframe using append\n",
    "df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
    "df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
    "df=df.append(df2,ignore_index=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concatenate multiple dataframe \n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']})\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']})\n",
    "\n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                    'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                    'D': ['D8', 'D9', 'D10', 'D11']})\n",
    "\n",
    "frames = [df1, df2, df3]\n",
    "\n",
    "result = pd.concat(frames, ignore_index=True)\n",
    "print(result) \n",
    "\n",
    "#save to csv file\n",
    "df1.to_csv('data-001.csv', encoding='utf-8', index=False)\n",
    "df2.to_csv('data-002.csv', encoding='utf-8', index=False)\n",
    "df3.to_csv('data-003.csv', encoding='utf-8', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from multiple .csv file and concatenate all datafram using append\n",
    "import os, sys,glob\n",
    "from pathlib import Path\n",
    "total_files=3\n",
    "path = \"./\" \n",
    "df=pd.DataFrame()  #empty dataframe\n",
    "#print(df.shape)\n",
    "for i in range(total_files):\n",
    "    buf = \"data-%03d.csv\"%(i+1)\n",
    "    buf=os.path.join(path,buf)\n",
    "    print(buf)\n",
    "    df2=pd.read_csv(buf)\n",
    "    df=df.append(df2,ignore_index=True)\n",
    "\n",
    "    \n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data from multiple .csv file and concatenate all datafram using concat\n",
    "import os, sys,glob\n",
    "from pathlib import Path\n",
    "total_files=3\n",
    "path = \"./\" \n",
    "df=pd.DataFrame()  #empty dataframe\n",
    "df_list=[]\n",
    "print(df.shape)\n",
    "for i in range(total_files):\n",
    "    buf = \"data-%03d.csv\"%(i+1)\n",
    "    buf=os.path.join(path,buf)\n",
    "    df_list.append(pd.read_csv(buf))\n",
    "\n",
    "#print(df_list[2])\n",
    "result = pd.concat(df_list, ignore_index=True)\n",
    "print(result) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[i] for i in range(10)], columns=['num'])\n",
    "print(df)\n",
    "def powers(x):\n",
    "    return x, x**2, x**3, x**4, x**5, x**6\n",
    "\n",
    "df['p1'], df['p2'], df['p3'], df['p4'], df['p5'], df['p6'] = \\\n",
    "    zip(*df['num'].map(powers))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Series : One-dimensional ndarray with axis labels\n",
    "\n",
    "df=pd.Series([1,2,3,4], index = ['a','b','c','d'])\n",
    "print(df)\n",
    "\n",
    "\n",
    "array=np.array(df, dtype=pd.Series)\n",
    "print(array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas\n",
    "#2-dimensional labeled data structure with columns of potentially different types\n",
    "import pandas as pd\n",
    "d={}\n",
    "d['A'] = pd.Series([1,2,3,4], index = ['a','b','c','d'])\n",
    "d['B'] = pd.Series([5,6,7,8], index = ['c','a','b','x'])\n",
    "d['C'] = pd.Series([2,1,2,4], index = ['c','a','b','d'])  #  Series內的 index 不能重複\n",
    "df = pd.DataFrame(d)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas\n",
    "#2-dimensional labeled data structure with columns of potentially different types\n",
    "\n",
    "d={}\n",
    "d['A'] = pd.Series([1,2,3,4], index = ['a','b','c','d'])\n",
    "d['B'] = pd.Series([5,6,7,8], index = ['c','a','b','x'])\n",
    "d['C'] = pd.Series([2,1,2,4], index = ['c','a','b','d'])  # index 不能重複\n",
    "df = pd.DataFrame(d,index=['d','c'],columns=['A','C'])  #只顯示index為'c'的, Column 只顯示 'A', \"C\" 兩欄\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['1', '2', '3']\n",
    "\n",
    "with open(\"file.txt\", \"w\") as output:\n",
    "    for s in values:\n",
    "        output.write(\"%s,\"%s)\n",
    "        \n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas groupby\n",
    "import numpy as np\n",
    "f = pd.DataFrame({'A' : ['foo', 'bar', 'foo', 'bar','foo', 'bar', 'foo', 'foo'],\n",
    "                  'B' : ['one', 'one', 'two', 'three','two', 'two', 'one', 'three'],\n",
    "                  'C' : np.random.randn(8),\n",
    "                  'D' : np.random.randn(8)})\n",
    "print(f)\n",
    "grouped = f.groupby(['A'])\n",
    "#group information\n",
    "print(grouped)\n",
    "print(grouped.groups)\n",
    "size = f.groupby('A').size()\n",
    "print(size)\n",
    "a=f.groupby(['A']).size().reset_index(name='count')\n",
    "print(a)\n",
    "print(a.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,date\n",
    "\n",
    "def process_time(stime):\n",
    "    #'2017-11-24 7:59:25.334'\n",
    "    time_slot=-1\n",
    "    date1,time1= stime.split(' ')\n",
    "    date1=[int(i) for i in date1.split('-')]   #[2017, 6, 8] Y/M/D\n",
    "    time1=[float(i) for i in time1.split(':')]  #[15.0, 18.0, 25.334] H/M/S\n",
    "    t=datetime(date1[0], date1[1],date1[2],int(time1[0]),int(time1[1])).time()\n",
    "\n",
    "    t0=t.replace(hour=1,minute=0)\n",
    "    t1=t.replace(hour=9,minute=0)\n",
    "    t2=t.replace(hour=17,minute=0)\n",
    "    t3=t.replace(hour=21,minute=0)\n",
    "    #print(t)\n",
    "    #print(t0)  #01:00:00\n",
    "\n",
    "    if (t>=t0 and t<t1): #AM1:00~AM9:00\n",
    "        time_slot=0\n",
    "    elif (t>=t1 and t<t2):  #AM9:00~PM17:00\n",
    "        time_slot=1\n",
    "    elif (t>=t2 and t<t3): #PM17:00~PM9:00 \n",
    "        time_slot=2\n",
    "    else:  # >PM 9:00\n",
    "        time_slot=3\n",
    "    # weekday\n",
    "    weekday=date(date1[0], date1[1],date1[2]).weekday()   #Modnday:0, Tuesday:1 ,...Sunday:6\n",
    "    \n",
    "    return weekday,time_slot \n",
    "\n",
    "def read_csv(files):\n",
    "    #column filter\n",
    "    \n",
    "    '''\n",
    "    all column list:\n",
    "    user_id,device_id,session_id,title_id,event_time,played_duration,\n",
    "    action_trigger,platform,episode_number,series_total_episodes_count,internet_connection_type,is_trailer\n",
    "    '''\n",
    "    #olny use partial column\n",
    "    cols=['user_id','event_time','played_duration']\n",
    "    df=pd.read_csv(files,usecols=cols)\n",
    "    return df\n",
    "\n",
    "def preprocess_Xdata():\n",
    "    print(\"concatenate all files\")\n",
    "    path = \"public/\" \n",
    "    allFiles=[]\n",
    "    total_files=2\n",
    "    for i in range(total_files):\n",
    "        buf = \"data-%03d.csv\"%(i+1)\n",
    "        buf=os.path.join(path,buf)\n",
    "        combine_file(buf)\n",
    "        allFiles.append(buf)\n",
    "        \n",
    "    print(allFiles)\n",
    "\n",
    "def preprocess_file(file):    \n",
    "    df=read_csv(file)\n",
    "\n",
    "    max_user_id=df.iloc[-1:, 0] # last row of column 0\n",
    "    max_id=np.array(max_user_id, dtype=pd.Series)[0] # series to ndarray\n",
    "    print(max_id)\n",
    "\n",
    "    user_timeslot_list=[]\n",
    "    #output file 'data.csv'\n",
    "    f = open('data.csv', 'w')\n",
    "    for i in range(max_id+1):\n",
    "        user_df=df[df['user_id']==i]\n",
    "        #print(user_df)\n",
    "        n_events=user_df.shape[0] #number of row\n",
    "        total_duration=0\n",
    "        time_slot=[0]*28\n",
    "        for row in user_df.itertuples(index=True):\n",
    "            weekday,slot=process_time(getattr(row, \"event_time\"))\n",
    "            #time_slot[weekday*4+slot]+=1 #event count in each timeslot\n",
    "            t=getattr(row, \"played_duration\")\n",
    "            time_slot[weekday*4+slot]+=t #event count in each timeslot\n",
    "            total_duration+=t\n",
    "\n",
    "        print(i,n_events,total_duration,time_slot)\n",
    "        #write file for each row\n",
    "        print('write file....')\n",
    "        f.write('%d,%d,%d,' %(i,n_events,total_duration))\n",
    "        for s in time_slot:\n",
    "            f.write('%s,' %(str(s)))\n",
    "        f.write('\\n')\n",
    "    return  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f.close()\n",
    "\n",
    "preprocess_Xdata()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
